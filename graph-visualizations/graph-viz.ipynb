{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CPG (Code Property Graph) - single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import networkx as nx\n",
    "\n",
    "class CPGBuilder(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.graph = nx.MultiDiGraph()\n",
    "        self.current_scope = \"global\"\n",
    "        self.node_counter = 0\n",
    "    \n",
    "    def generic_visit(self, node):\n",
    "        # Alapértelmezett viselkedés minden csomóponttípusra\n",
    "        node_id = self._add_node(node)\n",
    "        for field, value in ast.iter_fields(node):\n",
    "            if isinstance(value, ast.AST):\n",
    "                child_id = self.visit(value)\n",
    "                self.graph.add_edge(node_id, child_id, label=field)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ast.AST):\n",
    "                        child_id = self.visit(item)\n",
    "                        self.graph.add_edge(node_id, child_id, label=field)\n",
    "        return node_id\n",
    "    \n",
    "    def _add_node(self, node):\n",
    "        node_id = f\"{type(node).__name__}_{self.node_counter}\"\n",
    "        self.node_counter += 1\n",
    "        \n",
    "        # Alap attribútumok\n",
    "        attrs = {\n",
    "            'type': type(node).__name__,\n",
    "            'lineno': getattr(node, 'lineno', None),\n",
    "            'col_offset': getattr(node, 'col_offset', None)\n",
    "        }\n",
    "        \n",
    "        # Típus-specifikus attribútumok\n",
    "        if isinstance(node, ast.Name):\n",
    "            attrs['name'] = node.id\n",
    "        elif isinstance(node, ast.Constant):\n",
    "            attrs['value'] = node.value\n",
    "        elif isinstance(node, ast.FunctionDef):\n",
    "            attrs['name'] = node.name\n",
    "            self.current_scope = node.name\n",
    "        \n",
    "        self.graph.add_node(node_id, **attrs)\n",
    "        return node_id\n",
    "    \n",
    "    # Példa egy specifikus csomópultípus kezelésére\n",
    "    def visit_FunctionDef(self, node):\n",
    "        func_id = self._add_node(node)\n",
    "        \n",
    "        # Paraméterek hozzáadása\n",
    "        for arg in node.args.args:\n",
    "            arg_id = self.visit(arg)\n",
    "            self.graph.add_edge(func_id, arg_id, label='param')\n",
    "        \n",
    "        # Törzs hozzáadása\n",
    "        for stmt in node.body:\n",
    "            stmt_id = self.visit(stmt)\n",
    "            self.graph.add_edge(func_id, stmt_id, label='body')\n",
    "        \n",
    "        return func_id\n",
    "\n",
    "def build_cpg(source_code):\n",
    "    tree = ast.parse(source_code)\n",
    "    builder = CPGBuilder()\n",
    "    builder.visit(tree)\n",
    "    return builder.graph\n",
    "\n",
    "# Példa használat\n",
    "source = \"\"\"\n",
    "import time\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "from utils.learning_helpers import *\n",
    "from utils.lie_algebra import se3_log_exp\n",
    "import numpy as np\n",
    "from liegroups import SE3\n",
    "from pyslam.metrics import TrajectoryMetrics\n",
    "\n",
    "def Validate(device, pose_model, spatial_trans, dset, loss):\n",
    "    start = time.time()\n",
    "    pose_model.train(False)  # Set model to evaluate mode\n",
    "    pose_model.eval()        #used for batch normalization  # Set model to training mode\n",
    "    spatial_trans.train(False)  \n",
    "    spatial_trans.eval()        \n",
    "    dset_size = dset.dataset.__len__()\n",
    "    running_loss = 0.0           \n",
    "        # Iterate over data.\n",
    "    for data in dset:\n",
    "            # get the inputs\n",
    "        imgs, gt_lie_alg, intrinsics, vo_lie_alg, gt_correction = data\n",
    "        gt_lie_alg = gt_lie_alg.type(torch.FloatTensor).to(device) \n",
    "        vo_lie_alg = vo_lie_alg.type(torch.FloatTensor).to(device)\n",
    "        img_list = []\n",
    "        for im in imgs: \n",
    "            img_list.append(im.to(device))\n",
    "\n",
    "        intrinsics = intrinsics.type(torch.FloatTensor).to(device)[:,0,:,:] #only need one matrix since it's constant across the sequence\n",
    "  \n",
    "        corr, exp_mask, disparities = pose_model(img_list[0:3], vo_lie_alg)\n",
    "        pose = se3_log_exp(corr, vo_lie_alg)\n",
    "        minibatch_loss = loss.forward(img_list[-2], img_list[-1], pose, exp_mask, disparities, intrinsics, pose_vec_weight = vo_lie_alg, validate=True)\n",
    "\n",
    "        running_loss += minibatch_loss.item()\n",
    "     \n",
    "    epoch_loss = running_loss / float(dset_size) \n",
    "    print('Validation Loss: {:.6f}'.format(epoch_loss))\n",
    "    print(\"Validation epoch completed in {} seconds.\".format(timeSince(start)))\n",
    "    return epoch_loss\n",
    "\n",
    "def test_depth_and_reconstruction(device, pose_model, spatial_trans,  dset, img_idx=[0,100,200,300]):\n",
    "#    idx = np.random.randint(0,high=dset.dataset.__len__())\n",
    "    exp_mask_array = torch.zeros(0)\n",
    "    img_array = torch.zeros(0)\n",
    "    disp_array = torch.zeros(0)\n",
    "    for i in img_idx: #[1943,1944,1945,1946, 1947]:\n",
    "        imgs, gt_lie_alg, intrinsics, vo_lie_alg, gt_correction = dset.dataset.__getitem__(i)\n",
    "        gt_lie_alg = torch.FloatTensor(gt_lie_alg).to(device) \n",
    "        vo_lie_alg = torch.FloatTensor(vo_lie_alg).to(device)\n",
    "        img_list = []\n",
    "        for im in imgs:              \n",
    "            img_list.append(im.to(device).unsqueeze(0))\n",
    "        intrinsics = torch.FloatTensor(intrinsics).to(device)[0,:,:].unsqueeze(0)\n",
    "    \n",
    "        pose_model.train(False)  # Set model to evaluate mode\n",
    "        pose_model.eval()        #used for batch normalization  # Set model to training mode\n",
    "        spatial_trans.train(False)  \n",
    "        spatial_trans.eval()        \n",
    "        \n",
    "        corr, exp_mask, disp = pose_model(img_list[0:3], vo_lie_alg.unsqueeze(0))\n",
    "        ###comment for stereo\n",
    "        exp_mask, disp = exp_mask[0], disp[0]\n",
    "        disp = disp.unsqueeze(1)\n",
    "        disp_array = torch.cat((disp_array, disp[0].cpu().detach()))\n",
    "        depth = 1.0/disp[:,0].clone()\n",
    "        pose = se3_log_exp(corr, vo_lie_alg)\n",
    "\n",
    "        img_reconstructed = spatial_trans(img_list[-2], depth, -pose.clone(), intrinsics, intrinsics.inverse())    \n",
    "        imgs = torch.stack((img_list[-2],img_reconstructed,img_list[-1]),dim=1)[0].cpu().detach()\n",
    "        img_array = torch.cat((img_array, imgs))\n",
    "        if exp_mask is not None:\n",
    "            exp_mask = exp_mask.cpu().detach()\n",
    "            exp_mask_array = torch.cat((exp_mask_array, exp_mask))\n",
    "\n",
    "    return img_array, disp_array.numpy().squeeze(), exp_mask_array\n",
    "\n",
    "def test_trajectory(device, pose_model, spatial_trans, dset, epoch):\n",
    "    pose_model.train(False)  # Set model to evaluate mode\n",
    "    pose_model.eval()        #used for batch normalization  # Set model to training mode\n",
    "    spatial_trans.train(False)  \n",
    "    spatial_trans.eval()     \n",
    "    \n",
    "    #initialize the relevant outputs\n",
    "    full_corr_lie_alg_stacked, rot_corr_lie_alg_stacked, gt_lie_alg_stacked, vo_lie_alg_stacked, corrections_stacked, gt_corrections_stacked= \\\n",
    "            np.empty((0,6)), np.empty((0,6)), np.empty((0,6)), np.empty((0,6)), np.empty((0,6)), np.empty((0,6))\n",
    "\n",
    "    for data in dset:\n",
    "        imgs, gt_lie_alg, intrinsics, vo_lie_alg, gt_correction = data\n",
    "        gt_lie_alg = gt_lie_alg.type(torch.FloatTensor).to(device)   \n",
    "        vo_lie_alg = vo_lie_alg.type(torch.FloatTensor).to(device)\n",
    "        img_list = []\n",
    "        for im in imgs:              \n",
    "            img_list.append(im.to(device))\n",
    "\n",
    "        corr, exp_mask, disp = pose_model(img_list[0:3], vo_lie_alg)\n",
    "        exp_mask, disp = exp_mask[0], disp[0][:,0]\n",
    "        corr_rot = torch.clone(corr)\n",
    "        corr_rot[:,0:3]=0\n",
    "\n",
    "        corrected_pose = se3_log_exp(corr, vo_lie_alg)\n",
    "        corrected_pose_rot_only = se3_log_exp(corr_rot, vo_lie_alg)\n",
    "        \n",
    "        \n",
    "        corrections_stacked = np.vstack((corrections_stacked, corr.cpu().detach().numpy()))\n",
    "        gt_corrections_stacked = np.vstack((gt_corrections_stacked, gt_correction.cpu().detach().numpy()))\n",
    "        full_corr_lie_alg_stacked = np.vstack((full_corr_lie_alg_stacked, corrected_pose.cpu().detach().numpy()))\n",
    "        rot_corr_lie_alg_stacked = np.vstack((rot_corr_lie_alg_stacked, corrected_pose_rot_only.cpu().detach().numpy()))\n",
    "        gt_lie_alg_stacked = np.vstack((gt_lie_alg_stacked, gt_lie_alg.cpu().detach().numpy()))\n",
    "        vo_lie_alg_stacked = np.vstack((vo_lie_alg_stacked, vo_lie_alg.cpu().detach().numpy()))\n",
    "\n",
    "    est_traj, corr_traj, corr_traj_rot, gt_traj = [],[],[],[]\n",
    "    gt_traj = dset.dataset.raw_gt_trials[0]\n",
    "    est_traj.append(gt_traj[0])\n",
    "    corr_traj.append(gt_traj[0])\n",
    "    corr_traj_rot.append(gt_traj[0])\n",
    "\n",
    "    cum_dist = [0]\n",
    "    for i in range(0,full_corr_lie_alg_stacked.shape[0]):\n",
    "        #classically estimated traj\n",
    "        dT = SE3.exp(vo_lie_alg_stacked[i])\n",
    "        new_est = SE3.as_matrix((dT.dot(SE3.from_matrix(est_traj[i],normalize=True).inv())).inv())\n",
    "        est_traj.append(new_est)\n",
    "        cum_dist.append(cum_dist[i]+np.linalg.norm(dT.trans))\n",
    "\n",
    "        #corrected traj (rotation only)\n",
    "        dT = SE3.exp(rot_corr_lie_alg_stacked[i])\n",
    "        new_est = SE3.as_matrix((dT.dot(SE3.from_matrix(corr_traj_rot[i],normalize=True).inv())).inv())\n",
    "        corr_traj_rot.append(new_est)\n",
    "#        \n",
    "#        \n",
    "#        #corrected traj (full pose)\n",
    "        dT = SE3.exp(full_corr_lie_alg_stacked[i])\n",
    "        new_est = SE3.as_matrix((dT.dot(SE3.from_matrix(corr_traj[i],normalize=True).inv())).inv())\n",
    "        corr_traj.append(new_est)\n",
    "\n",
    "    gt_traj_se3 = [SE3.from_matrix(T,normalize=True) for T in gt_traj]\n",
    "    est_traj_se3 = [SE3.from_matrix(T,normalize=True) for T in est_traj]\n",
    "    corr_traj_se3 = [SE3.from_matrix(T,normalize=True) for T in corr_traj]\n",
    "    corr_traj_rot_se3 = [SE3.from_matrix(T,normalize=True) for T in corr_traj_rot]\n",
    "    \n",
    "    tm_est = TrajectoryMetrics(gt_traj_se3, est_traj_se3, convention = 'Twv')\n",
    "    tm_corr = TrajectoryMetrics(gt_traj_se3, corr_traj_se3, convention = 'Twv')\n",
    "    tm_corr_rot = TrajectoryMetrics(gt_traj_se3, corr_traj_rot_se3, convention = 'Twv')\n",
    "    \n",
    "    if epoch >= 0:\n",
    "        est_mean_trans, est_mean_rot = tm_est.mean_err()\n",
    "        corr_mean_trans, corr_mean_rot = tm_corr.mean_err()\n",
    "        corr_rot_mean_trans, corr_rot_mean_rot = tm_corr_rot.mean_err()\n",
    "        print(\"Odom. mean trans. error: {} | mean rot. error: {}\".format(est_mean_trans, est_mean_rot*180/np.pi))\n",
    "        print(\"Corr. mean trans. error: {} | mean rot. error: {}\".format(corr_mean_trans, corr_mean_rot*180/np.pi))\n",
    "        print(\"Corr. (rot. only) mean trans. error: {} | mean rot. error: {}\".format(corr_rot_mean_trans, corr_rot_mean_rot*180/np.pi))\n",
    "        \n",
    "        seg_lengths = list(range(100,801,100))\n",
    "        _, seg_errs_est = tm_est.segment_errors(seg_lengths, rot_unit='rad')\n",
    "        _, seg_errs_corr = tm_corr.segment_errors(seg_lengths, rot_unit='rad')\n",
    "        _, seg_errs_corr_rot = tm_corr_rot.segment_errors(seg_lengths, rot_unit='rad')\n",
    "        print(\"Odom. mean Segment Errors: {} (trans, %) | {} (rot, deg/100m)\".format(np.mean(seg_errs_est[:,1])*100, 100*np.mean(seg_errs_est[:,2])*180/np.pi))\n",
    "        print(\"Corr. mean Segment Errors: {} (trans, %) | {} (rot, deg/100m)\".format(np.mean(seg_errs_corr[:,1])*100, 100*np.mean(seg_errs_corr[:,2])*180/np.pi))\n",
    "        print(\"Corr. (rot. only) mean Segment Errors: {} (trans, %) | {} (rot, deg/100m)\".format(np.mean(seg_errs_corr_rot[:,1])*100, 100*np.mean(seg_errs_corr_rot[:,2])*180/np.pi)) \n",
    "        \n",
    "    rot_seg_err = 100*np.mean(seg_errs_corr_rot[:,2])*180/np.pi\n",
    "\n",
    "    return corrections_stacked, gt_corrections_stacked, full_corr_lie_alg_stacked, vo_lie_alg_stacked, gt_lie_alg_stacked, \\\n",
    "        np.array(corr_traj), np.array(corr_traj_rot), np.array(est_traj), np.array(gt_traj), rot_seg_err, corr_rot_mean_trans, np.array(cum_dist)\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "cpg = build_cpg(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPG visualization saved to None\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_cpg_pyvis(cpg, filename=\"cpg.html\"):\n",
    "    # Create PyVis network\n",
    "    net = Network(\n",
    "        directed=True,\n",
    "        height=\"1000px\",\n",
    "        width=\"100%\",\n",
    "        notebook=False,\n",
    "        bgcolor=\"#222222\",\n",
    "        font_color=\"white\"\n",
    "    )\n",
    "    \n",
    "    # Add nodes with all attributes\n",
    "    for node, data in cpg.nodes(data=True):\n",
    "        net.add_node(\n",
    "            node,\n",
    "            label=data.get('label', data['type']),\n",
    "            title=data.get('title', \"\"),\n",
    "            group=data['type'],  # Group by node type\n",
    "            shape=\"box\",\n",
    "            color={\n",
    "                'FunctionDef': '#FF6B6B',\n",
    "                'Name': '#4ECDC4',\n",
    "                'Constant': '#FFE66D',\n",
    "                'If': '#A5D8FF',\n",
    "                'Call': '#C8A2C8'\n",
    "            }.get(data['type'], '#7FB3D5')\n",
    "        )\n",
    "    \n",
    "    # Add edges with labels\n",
    "    for u, v, data in cpg.edges(data=True):\n",
    "        net.add_edge(u, v, label=data.get('label', ''), color='#888888')\n",
    "    \n",
    "    # Configure physics for better layout\n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    \n",
    "    # Save to HTML file\n",
    "    net.save_graph(filename)\n",
    "\n",
    "def build_and_visualize(source_code, output_file=\"cpg.html\"):\n",
    "    tree = ast.parse(source_code)\n",
    "    builder = CPGBuilder()\n",
    "    builder.visit(tree)\n",
    "    return visualize_cpg_pyvis(builder.graph, output_file)\n",
    "\n",
    "output_html = build_and_visualize(source, \"factorial_cpg.html\")\n",
    "print(f\"CPG visualization saved to {output_html}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CPG (Code Property Graph) - multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:83: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:84: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:85: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<unknown>:152: SyntaxWarning: invalid escape sequence '\\%'\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import networkx as nx\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class MultiFileCPGBuilder:\n",
    "    def __init__(self):\n",
    "        self.graph = nx.MultiDiGraph()\n",
    "        self.node_counter = 0\n",
    "        self.current_scope = []\n",
    "        self.file_nodes = {}  # Fájlokhoz tartozó root node-ok\n",
    "        \n",
    "    def add_source_file(self, file_path, source_code):\n",
    "        # Fájl root node hozzáadása\n",
    "        file_id = f\"File_{os.path.basename(file_path)}_{self.node_counter}\"\n",
    "        self.node_counter += 1\n",
    "        self.graph.add_node(file_id, type='File', name=file_path, path=str(file_path))\n",
    "        self.file_nodes[file_path] = file_id\n",
    "        \n",
    "        # AST elemzés\n",
    "        tree = ast.parse(source_code)\n",
    "        visitor = FileVisitor(self.graph, self.node_counter, self.current_scope.copy())\n",
    "        visitor.visit(tree)\n",
    "        \n",
    "        # Kapcsolat a fájl node és a globális elemek között\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.AsyncFunctionDef)):\n",
    "                def_id = f\"{type(node).__name__}_{node.name}_{visitor.node_counter}\"\n",
    "                if def_id in visitor.local_ids:\n",
    "                    self.graph.add_edge(file_id, def_id, label='contains')\n",
    "        \n",
    "        # Frissítjük a node számlálót\n",
    "        self.node_counter = visitor.node_counter\n",
    "        \n",
    "        return file_id\n",
    "\n",
    "class FileVisitor(ast.NodeVisitor):\n",
    "    def __init__(self, graph, start_counter, current_scope):\n",
    "        self.graph = graph\n",
    "        self.node_counter = start_counter\n",
    "        self.current_scope = current_scope\n",
    "        self.local_ids = set()\n",
    "    \n",
    "    def _add_node(self, node, extra_attrs=None):\n",
    "        node_id = f\"{type(node).__name__}_{self.node_counter}\"\n",
    "        self.node_counter += 1\n",
    "        \n",
    "        attrs = {\n",
    "            'type': type(node).__name__,\n",
    "            'lineno': getattr(node, 'lineno', None),\n",
    "            'col_offset': getattr(node, 'col_offset', None),\n",
    "            'scope': '::'.join(self.current_scope) if self.current_scope else 'global'\n",
    "        }\n",
    "        \n",
    "        if extra_attrs:\n",
    "            attrs.update(extra_attrs)\n",
    "        \n",
    "        if isinstance(node, ast.Name):\n",
    "            attrs['name'] = node.id\n",
    "        elif isinstance(node, ast.Constant):\n",
    "            attrs['value'] = node.value\n",
    "        elif isinstance(node, ast.FunctionDef):\n",
    "            attrs['name'] = node.name\n",
    "            attrs['label'] = f\"Function: {node.name}\"\n",
    "        \n",
    "        self.graph.add_node(node_id, **attrs)\n",
    "        self.local_ids.add(node_id)\n",
    "        return node_id\n",
    "    \n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.current_scope.append(node.name)\n",
    "        func_id = self._add_node(node, {'name': node.name})\n",
    "        \n",
    "        # Paraméterek\n",
    "        for arg in node.args.args:\n",
    "            arg_id = self._add_node(arg, {'name': arg.arg})\n",
    "            self.graph.add_edge(func_id, arg_id, label='param')\n",
    "        \n",
    "        # Törzs\n",
    "        for stmt in node.body:\n",
    "            stmt_id = self.visit(stmt)\n",
    "            self.graph.add_edge(func_id, stmt_id, label='body')\n",
    "        \n",
    "        self.current_scope.pop()\n",
    "        return func_id\n",
    "    \n",
    "    def visit_ClassDef(self, node):\n",
    "        self.current_scope.append(node.name)\n",
    "        class_id = self._add_node(node, {'name': node.name})\n",
    "        \n",
    "        # Osztály törzse\n",
    "        for stmt in node.body:\n",
    "            stmt_id = self.visit(stmt)\n",
    "            self.graph.add_edge(class_id, stmt_id, label='body')\n",
    "        \n",
    "        self.current_scope.pop()\n",
    "        return class_id\n",
    "    \n",
    "    def generic_visit(self, node):\n",
    "        node_id = self._add_node(node)\n",
    "        for field, value in ast.iter_fields(node):\n",
    "            if isinstance(value, ast.AST):\n",
    "                child_id = self.visit(value)\n",
    "                self.graph.add_edge(node_id, child_id, label=field)\n",
    "            elif isinstance(value, list):\n",
    "                for item in value:\n",
    "                    if isinstance(item, ast.AST):\n",
    "                        child_id = self.visit(item)\n",
    "                        self.graph.add_edge(node_id, child_id, label=field)\n",
    "        return node_id\n",
    "\n",
    "def build_multi_file_cpg(source_files):\n",
    "    \"\"\"\n",
    "    source_files: dictionary {file_path: source_code}\n",
    "    \"\"\"\n",
    "    builder = MultiFileCPGBuilder()\n",
    "    \n",
    "    for file_path, source_code in source_files.items():\n",
    "        builder.add_source_file(file_path, source_code)\n",
    "    \n",
    "    return builder.graph\n",
    "\n",
    "# Példa használat:\n",
    "def load_source_files(directory):\n",
    "    source_files = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.py'):\n",
    "                path = Path(root) / file\n",
    "                with open(path, 'r', encoding='utf-8') as f:\n",
    "                    source_files[str(path)] = f.read()\n",
    "    return source_files\n",
    "\n",
    "# Kódbázis beolvasása\n",
    "source_files = load_source_files('repos/ss-dpc-net_python')\n",
    "\n",
    "# CPG létrehozása\n",
    "cpg = build_multi_file_cpg(source_files)\n",
    "\n",
    "# Gráf vizualizáció (használd a korábbi PyVis megoldást)\n",
    "visualize_cpg_pyvis(cpg, \"full_codebase_cpg.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CFG (Control Flow Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(process:36592): Pango-WARNING **: 22:46:11.154: couldn't load font \"DejaVu Sans Mono Not-Rotated 14\", falling back to \"Sans Not-Rotated 14\", expect ugly output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output_cfg.pdf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py2cfg import CFGBuilder\n",
    "\n",
    "# CFG építése egy szkripthez\n",
    "cfg = CFGBuilder().build_from_file('example', 'repos/ss-dpc-net_python/train_mono.py')\n",
    "cfg.build_visual('output_cfg', 'pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CFG' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m edges_data = []\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Node-ok bejárása és adatok gyűjtése\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node_id, node \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m.items():\n\u001b[32m      7\u001b[39m     nodes_data.append({\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mnode_id\u001b[39m\u001b[33m'\u001b[39m: node_id,\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(node),\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33min_edges\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(node.incoming)\n\u001b[32m     14\u001b[39m     })\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# Élek gyűjtése (a node outgoining élein keresztül)\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'CFG' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "# Adatok gyűjtésére szolgáló listák\n",
    "nodes_data = []\n",
    "edges_data = []\n",
    "\n",
    "# Node-ok bejárása és adatok gyűjtése\n",
    "for node_id, node in cfg.nodes.items():\n",
    "    nodes_data.append({\n",
    "        'node_id': node_id,\n",
    "        'label': str(node),\n",
    "        'line_number': getattr(node, 'lineno', None),\n",
    "        'type': type(node).__name__,\n",
    "        'out_edges': len(node.outgoing),\n",
    "        'in_edges': len(node.incoming)\n",
    "    })\n",
    "    \n",
    "    # Élek gyűjtése (a node outgoining élein keresztül)\n",
    "    for edge in node.outgoing:\n",
    "        edges_data.append({\n",
    "            'source': node_id,\n",
    "            'target': edge.target.id,\n",
    "            'label': edge.label if hasattr(edge, 'label') else None,\n",
    "            'edge_type': type(edge).__name__\n",
    "        })\n",
    "\n",
    "# DataFrame-ek létrehozása\n",
    "nodes_df = pd.DataFrame(nodes_data)\n",
    "edges_df = pd.DataFrame(edges_data)\n",
    "\n",
    "# Megjelenítés\n",
    "print(\"Node-ok:\")\n",
    "print(nodes_df.head())\n",
    "print(\"\\nÉlek:\")\n",
    "print(edges_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GZ Call graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1232</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>1232</td>\n",
       "      <td>1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945</th>\n",
       "      <td>1232</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>1232</td>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>1232</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       src  target\n",
       "0        2       1\n",
       "1        2       3\n",
       "2        2       4\n",
       "3        2       8\n",
       "4        2      17\n",
       "...    ...     ...\n",
       "1943  1232    1355\n",
       "1944  1232    1356\n",
       "1945  1232    1357\n",
       "1946  1232    1358\n",
       "1947  1232    1359\n",
       "\n",
       "[1948 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_ids = pd.read_csv('bsc-code/gz/onlab/output_dir/processed_combined_method_nodes.csv', header=None)\n",
    "nodes = pd.read_csv('bsc-code/gz/onlab/output_dir/nodes_token_ready.csv', header=None)\n",
    "edges = pd.read_csv('bsc-code/gz/onlab/output_dir/method_only_edges.csv', header=None)\n",
    "\n",
    "\n",
    "nodes['OGID'] = node_ids[0]\n",
    "nodes['ID'] = nodes.index\n",
    "\n",
    "edges = edges.merge(nodes[['OGID', 'ID']].rename(columns={'ID': 'src'}), left_on=0, right_on='OGID', how='left').drop(columns=['OGID'])\n",
    "edges = edges.merge(nodes[['OGID', 'ID']].rename(columns={'ID': 'target'}), left_on=1, right_on='OGID', how='left').drop(columns=['OGID', 0, 1])\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1360, 354], edge_index=[1948, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create pyg graph\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "\n",
    "pyg = Data(x=torch.tensor(nodes.values), edge_index=torch.tensor(edges.values))\n",
    "pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a pyg graph using PyVis\n",
    "def visualize_pyg_graph(pyg_data, filename=\"pyg_graph.html\"):\n",
    "    net = Network(directed=True)\n",
    "    \n",
    "    # Add nodes\n",
    "    for i in range(pyg_data.num_nodes):\n",
    "        net.add_node(i, label=str(pyg_data.x[i].tolist()))\n",
    "    \n",
    "    # Add edges\n",
    "    for edge in pyg_data.edge_index.tolist():\n",
    "        net.add_edge(edge[0], edge[1])\n",
    "    \n",
    "    # Save to HTML file\n",
    "    net.save_graph(filename)\n",
    "\n",
    "\n",
    "visualize_pyg_graph(pyg, \"pyg_graph.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
